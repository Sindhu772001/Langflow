{"name": "Ticket_Classification", "description": "Building Intelligent Interactions.", "icon": null, "icon_bg_color": null, "gradient": null, "data": {"nodes": [{"id": "ChatInput-dcPER", "type": "genericNode", "position": {"x": -375.2021505741286, "y": 36.147773421959286}, "data": {"node": {"template": {"_type": "Component", "files": {"trace_as_metadata": true, "file_path": "", "fileTypes": ["txt", "md", "mdx", "csv", "json", "yaml", "yml", "xml", "html", "htm", "pdf", "docx", "py", "sh", "sql", "js", "ts", "tsx", "jpg", "jpeg", "png", "bmp", "image"], "list": true, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "files", "value": "", "display_name": "Files", "advanced": true, "dynamic": false, "info": "Files to be sent with the message.", "title_case": false, "type": "file", "_input_type": "FileInput"}, "background_color": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "background_color", "value": "", "display_name": "Background Color", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The background color of the icon.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "chat_icon": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "chat_icon", "value": "", "display_name": "Icon", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The icon of the message.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "input_value": {"tool_mode": false, "trace_as_input": true, "multiline": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "input_value", "value": "________________________________________ From: msp@promenet.com <msp@promenet.com> Sent: Tuesday, March 11, 2025 6:31:25 AM (UTC+00:00) Monrovia, Reykjavik To: N-ABLE-L1 Subject: Recovery: Select Equity - MA > Toronto: APC UPS on Toronto-UPS has returned to normal Customer: Select Equity - MA > Toronto Device: Toronto-UPS Service: APC UPS - State Transition: From Warning to Normal Time Of State Transition: 2025-03-11 02:30:55 Notification Generated By: Warnings", "display_name": "Text", "advanced": false, "input_types": [], "dynamic": false, "info": "Message to be passed as input.", "title_case": false, "type": "str", "_input_type": "MultilineInput"}, "sender": {"tool_mode": false, "trace_as_metadata": true, "options": ["Machine", "User"], "options_metadata": [], "combobox": false, "dialog_inputs": {}, "required": false, "placeholder": "", "show": true, "name": "sender", "value": "User", "display_name": "Sender Type", "advanced": true, "dynamic": false, "info": "Type of sender.", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "sender_name": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "sender_name", "value": "User", "display_name": "Sender Name", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "Name of the sender.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "session_id": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "session_id", "value": "", "display_name": "Session ID", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The session ID of the chat. If empty, the current session ID parameter will be used.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "should_store_message": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "should_store_message", "value": true, "display_name": "Store Messages", "advanced": true, "dynamic": false, "info": "Store the message in the history.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "text_color": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "text_color", "value": "", "display_name": "Text Color", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The text color of the name", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}}, "description": "Get chat inputs from the Playground.", "icon": "MessagesSquare", "base_classes": ["Message"], "display_name": "Chat Input", "documentation": "", "minimized": true, "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "message", "display_name": "Message", "method": "message_response", "value": "__UNDEFINED__", "cache": true, "allows_loop": false}], "field_order": ["input_value", "should_store_message", "sender", "sender_name", "session_id", "files", "background_color", "chat_icon", "text_color"], "beta": false, "legacy": false, "edited": false, "metadata": {}, "tool_mode": false, "lf_version": "1.1.5"}, "showNode": true, "type": "ChatInput", "id": "ChatInput-dcPER"}, "selected": false, "measured": {"width": 320, "height": 229}, "dragging": false}, {"id": "OpenAIModel-nDDz9", "type": "genericNode", "position": {"x": 482.42804331977527, "y": -229.58997748095052}, "data": {"node": {"template": {"_type": "Component", "api_key": {"load_from_db": false, "required": true, "placeholder": "", "show": true, "name": "api_key", "value": null, "display_name": "OpenAI API Key", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "The OpenAI API Key to use for the OpenAI model.", "title_case": false, "password": true, "type": "str", "_input_type": "SecretStrInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            request_timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "input_value": {"trace_as_input": true, "tool_mode": false, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "input_value", "value": "", "display_name": "Input", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "MessageInput"}, "json_mode": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "json_mode", "value": false, "display_name": "JSON Mode", "advanced": true, "dynamic": false, "info": "If True, it will output JSON regardless of passing a schema.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "max_retries": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "max_retries", "value": 5, "display_name": "Max Retries", "advanced": true, "dynamic": false, "info": "The maximum number of retries to make when generating.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "max_tokens": {"tool_mode": false, "trace_as_metadata": true, "range_spec": {"step_type": "float", "min": 0, "max": 128000, "step": 0.1}, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "max_tokens", "value": "", "display_name": "Max Tokens", "advanced": true, "dynamic": false, "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "model_kwargs": {"tool_mode": false, "trace_as_input": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "model_kwargs", "value": {}, "display_name": "Model Kwargs", "advanced": true, "dynamic": false, "info": "Additional keyword arguments to pass to the model.", "title_case": false, "type": "dict", "_input_type": "DictInput"}, "model_name": {"tool_mode": false, "trace_as_metadata": true, "options": ["gpt-4o-mini", "gpt-4o", "gpt-4-turbo", "gpt-4-turbo-preview", "gpt-4", "gpt-3.5-turbo", "gpt-3.5-turbo-0125", "unsloth-llama3.1"], "options_metadata": [], "combobox": false, "dialog_inputs": {}, "required": false, "placeholder": "", "show": true, "name": "model_name", "value": "unsloth-llama3.1", "display_name": "Model Name", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "str", "_input_type": "DropdownInput", "load_from_db": false}, "openai_api_base": {"tool_mode": false, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "openai_api_base", "value": "https://dev-vllm-unsloth.bautomate.com/v1", "display_name": "OpenAI API Base", "advanced": true, "dynamic": false, "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.", "title_case": false, "type": "str", "_input_type": "StrInput"}, "seed": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "seed", "value": 1, "display_name": "Seed", "advanced": true, "dynamic": false, "info": "The seed controls the reproducibility of the job.", "title_case": false, "type": "int", "_input_type": "IntInput"}, "stream": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "stream", "value": false, "display_name": "Stream", "advanced": false, "dynamic": false, "info": "Stream the response from the model. Streaming works only in Chat.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "system_message": {"tool_mode": false, "trace_as_input": true, "multiline": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "system_message", "value": "admin", "display_name": "System Message", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "System message to pass to the model.", "title_case": false, "type": "str", "_input_type": "MultilineInput"}, "temperature": {"tool_mode": false, "min_label": "", "max_label": "", "min_label_icon": "", "max_label_icon": "", "slider_buttons": false, "slider_buttons_options": [], "slider_input": false, "range_spec": {"step_type": "float", "min": 0, "max": 1, "step": 0.01}, "required": false, "placeholder": "", "show": true, "name": "temperature", "value": 0.1, "display_name": "Temperature", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "slider", "_input_type": "SliderInput"}, "timeout": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "timeout", "value": 700, "display_name": "Timeout", "advanced": true, "dynamic": false, "info": "The timeout for requests to OpenAI completion API.", "title_case": false, "type": "int", "_input_type": "IntInput"}}, "description": "Generates text using OpenAI LLMs.", "icon": "OpenAI", "base_classes": ["LanguageModel", "Message"], "display_name": "OpenAI", "documentation": "", "minimized": false, "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "text_output", "hidden": null, "display_name": "Message", "method": "text_response", "value": "__UNDEFINED__", "cache": true, "required_inputs": [], "allows_loop": false, "tool_mode": true}, {"types": ["LanguageModel"], "selected": "LanguageModel", "name": "model_output", "hidden": null, "display_name": "Language Model", "method": "build_model", "value": "__UNDEFINED__", "cache": true, "required_inputs": ["api_key"], "allows_loop": false, "tool_mode": true}], "field_order": ["input_value", "system_message", "stream", "max_tokens", "model_kwargs", "json_mode", "model_name", "openai_api_base", "api_key", "temperature", "seed", "max_retries", "timeout"], "beta": false, "legacy": false, "edited": false, "metadata": {}, "tool_mode": false, "lf_version": "1.1.5"}, "showNode": true, "type": "OpenAIModel", "id": "OpenAIModel-nDDz9", "description": "Generates text using OpenAI LLMs.", "display_name": "OpenAI"}, "selected": false, "measured": {"width": 320, "height": 653}, "dragging": false}, {"id": "Prompt-pe0FQ", "type": "genericNode", "position": {"x": 29.28538425703769, "y": -198.25046473720718}, "data": {"node": {"template": {"_type": "Component", "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "template": {"tool_mode": false, "trace_as_input": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "template", "value": "You are an intelligent ITSM ticket classifier and extractor. \nYour task is to analyze the provided ITSM ticket, which may be an email or an automatically generated monitoring log. \nIf the ticket is an automatically generated monitoring log, treat it as an email for classification purposes. \nYour responsibilities include determining its severity, dynamically identifying the issue category, and suggesting an appropriate action plan based on its content. Even if specific details are not explicitly mentioned, you should infer and classify the ticket, determine its category, and recommend suitable actions.\n\nInstructions:\n\n1. Classification: Classify the severity of the issue into one of the following categories:\n   - L1 (Low): Informational or non-urgent tasks. Examples: Minor application error with no business impact (e.g., UI misalignment in internal software), scheduling firmware updates for non-critical devices, requests for access to shared folders, general inquiries regarding system documentation or training materials.\n   - L2 (Medium): Minor issues or low priority. Examples: Network latency impacting specific users (e.g., slow intranet performance), analyzing recurring performance degradation in an internal application, printer configuration issues causing minor delays, non-critical software bug fixes, request for software installation for new hires.\n   - L3 (High): Issues that require technical intervention, but are not critical. Examples: VPN connectivity issues affecting a remote team, implementing a network topology change that affects active users, email delivery failure for multiple users, security patch updates for vulnerability mitigation, configuration errors in firewall rules impacting access control.\n   - L4 (Critical): Major issues that need immediate resolution. Examples: Data center outage causing service unavailability for all users, emergency patch deployment to fix a vulnerability exploited in an ongoing attack, server hardware failure causing downtime for critical systems, database corruption resulting in data loss and service disruption, ransomware attack impacting business operations.\n\n2. Categorize the following components appropriately:\n\n- Switch/Router(Physical Components): Should we categorize by physical component? E.g. Fans, PSU etc.\n- UPS(Physical Components): Should we categorize by physical component? E.g. Battery, Network Card etc.\n- Physical Windows servers(Physical components): Should we categorize by physical component? E.g. Fans, PSU etc.\n- Windows Server: Should we categorize by services? E.g. CPU, Memory, Disk space etc.\n- ESXi servers(Physical Component): Should we categorize by physical component? E.g. Fans, PSU etc.\n- Storage appliances: Should we categorize by physical component? E.g. Fans, PSU etc.\n- Backup Jobs: Should we categorize by vendor? Veeam, Barracuda etc.\n- Wireless Access Points: Should we categorize by vendor? Meraki, Aruba etc.\n- Security Management: Should we categorize by vendor? Crowdstrike, Cisco etc.\n\n\n3. Priority: Based on the classification and severity, determine the priority as:\n   - High\n   - Medium\n   - Low\n\n4. Suggested Action: Based on the category and severity of the issue, suggest an appropriate action plan.\n\n5. Action Plan: Provide the steps or actions needed to resolve the issue.\n\n6. Information Field: Dynamically retrieve all the relevant details from the email. The information field must be flexible and adapt to the structure of each incoming email. These fields will be populated dynamically depending on the content of the email and they can change with each ticket.\n\nOutput Structure:\nThe output should follow this structure:\n\n[\n    {{\"classification\": \"L1 (Low) / L2 (Medium) / L3 (High) / L4 (Critical)\"}},\n    {{\"subject\": \"Ticket issue summary\"}},\n    {{\"description\": \"Detailed issue description\"}},\n    {{\"category\": \"Switch or Router (Physical Components) / UPS (Physical Components) / Physical Windows Servers (Physical Components) / Windows Server / ESXi Servers (Physical Components) / Storage Appliances (Physical Components) / Backup Jobs / Wireless Access Points / Security Management\"}},\n    {{\"priority\": \"High / Medium / Low\"}},\n    {{\"suggestedAction\": \"Suggested actions to resolve the issue\"}},\n    {{\"information\": \"field1\": \"value1\"/\"field2\": \"value2\"}},\n    {{\"actionPlan\": \"step1\": \"Step description\"/\"step2\": \"Step description\"}}\n    ]}}\n]\n\nNotes:\n- The information field must be dynamically generated based on the contents of the email and can vary with each ticket. The fields and values in the information field will differ based on the specific email received.\n- The system should automatically classify, categorize and provide suggested actions without explicit instructions in the email.\n- The structure and contents of the information field should adapt to the ticket details in each email.\n- If any information is missing in the input email, return as empty string or NA.\n- Return only the above json format and not any other explanation\n{content}", "display_name": "Template", "advanced": false, "dynamic": false, "info": "", "title_case": false, "type": "prompt", "_input_type": "PromptInput"}, "tool_placeholder": {"tool_mode": true, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "tool_placeholder", "value": "", "display_name": "Tool Placeholder", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "A placeholder input for tool mode.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "content": {"field_type": "str", "required": false, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "", "fileTypes": [], "file_path": "", "name": "content", "display_name": "content", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "", "load_from_db": false, "title_case": false, "type": "str"}}, "description": "Create a prompt template with dynamic variables.", "icon": "prompts", "is_input": null, "is_output": null, "is_composition": null, "base_classes": ["Message"], "name": "", "display_name": "Prompt", "documentation": "", "minimized": false, "custom_fields": {"template": ["content"]}, "output_types": [], "full_path": null, "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "prompt", "hidden": null, "display_name": "Prompt Message", "method": "build_prompt", "value": "__UNDEFINED__", "cache": true, "required_inputs": null, "allows_loop": false}], "field_order": ["template", "tool_placeholder"], "beta": false, "legacy": false, "error": null, "edited": false, "metadata": {}, "tool_mode": false, "lf_version": "1.1.5"}, "showNode": true, "type": "Prompt", "id": "Prompt-pe0FQ"}, "selected": true, "measured": {"width": 320, "height": 337}, "dragging": false}, {"id": "JSONCleaner-7Yu2E", "type": "genericNode", "position": {"x": 882.170337288613, "y": -46.14359413284979}, "data": {"node": {"template": {"_type": "Component", "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "import json\nimport unicodedata\n\nfrom langflow.custom import Component\nfrom langflow.inputs import BoolInput, MessageTextInput\nfrom langflow.schema.message import Message\nfrom langflow.template import Output\n\n\nclass JSONCleaner(Component):\n    icon = \"braces\"\n    display_name = \"JSON Cleaner\"\n    description = (\n        \"Cleans the messy and sometimes incorrect JSON strings produced by LLMs \"\n        \"so that they are fully compliant with the JSON spec.\"\n    )\n\n    inputs = [\n        MessageTextInput(\n            name=\"json_str\", display_name=\"JSON String\", info=\"The JSON string to be cleaned.\", required=True\n        ),\n        BoolInput(\n            name=\"remove_control_chars\",\n            display_name=\"Remove Control Characters\",\n            info=\"Remove control characters from the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"normalize_unicode\",\n            display_name=\"Normalize Unicode\",\n            info=\"Normalize Unicode characters in the JSON string.\",\n            required=False,\n        ),\n        BoolInput(\n            name=\"validate_json\",\n            display_name=\"Validate JSON\",\n            info=\"Validate the JSON string to ensure it is well-formed.\",\n            required=False,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Cleaned JSON String\", name=\"output\", method=\"clean_json\"),\n    ]\n\n    def clean_json(self) -> Message:\n        try:\n            from json_repair import repair_json\n        except ImportError as e:\n            msg = \"Could not import the json_repair package. Please install it with `pip install json_repair`.\"\n            raise ImportError(msg) from e\n\n        \"\"\"Clean the input JSON string based on provided options and return the cleaned JSON string.\"\"\"\n        json_str = self.json_str\n        remove_control_chars = self.remove_control_chars\n        normalize_unicode = self.normalize_unicode\n        validate_json = self.validate_json\n\n        start = json_str.find(\"{\")\n        end = json_str.rfind(\"}\")\n        if start == -1 or end == -1:\n            msg = \"Invalid JSON string: Missing '{' or '}'\"\n            raise ValueError(msg)\n        try:\n            json_str = json_str[start : end + 1]\n\n            if remove_control_chars:\n                json_str = self._remove_control_characters(json_str)\n            if normalize_unicode:\n                json_str = self._normalize_unicode(json_str)\n            if validate_json:\n                json_str = self._validate_json(json_str)\n\n            cleaned_json_str = repair_json(json_str)\n            result = str(cleaned_json_str)\n\n            self.status = result\n            return Message(text=result)\n        except Exception as e:\n            msg = f\"Error cleaning JSON string: {e}\"\n            raise ValueError(msg) from e\n\n    def _remove_control_characters(self, s: str) -> str:\n        \"\"\"Remove control characters from the string.\"\"\"\n        return s.translate(self.translation_table)\n\n    def _normalize_unicode(self, s: str) -> str:\n        \"\"\"Normalize Unicode characters in the string.\"\"\"\n        return unicodedata.normalize(\"NFC\", s)\n\n    def _validate_json(self, s: str) -> str:\n        \"\"\"Validate the JSON string.\"\"\"\n        try:\n            json.loads(s)\n        except json.JSONDecodeError as e:\n            msg = f\"Invalid JSON string: {e}\"\n            raise ValueError(msg) from e\n        return s\n\n    def __init__(self, *args, **kwargs):\n        # Create a translation table that maps control characters to None\n        super().__init__(*args, **kwargs)\n        self.translation_table = str.maketrans(\"\", \"\", \"\".join(chr(i) for i in range(32)) + chr(127))\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "json_str": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": true, "placeholder": "", "show": true, "name": "json_str", "value": "", "display_name": "JSON String", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "The JSON string to be cleaned.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "normalize_unicode": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "normalize_unicode", "value": false, "display_name": "Normalize Unicode", "advanced": false, "dynamic": false, "info": "Normalize Unicode characters in the JSON string.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "remove_control_chars": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "remove_control_chars", "value": false, "display_name": "Remove Control Characters", "advanced": false, "dynamic": false, "info": "Remove control characters from the JSON string.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "validate_json": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "validate_json", "value": false, "display_name": "Validate JSON", "advanced": false, "dynamic": false, "info": "Validate the JSON string to ensure it is well-formed.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}}, "description": "Cleans the messy and sometimes incorrect JSON strings produced by LLMs so that they are fully compliant with the JSON spec.", "icon": "braces", "base_classes": ["Message"], "display_name": "JSON Cleaner", "documentation": "", "minimized": false, "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "output", "display_name": "Cleaned JSON String", "method": "clean_json", "value": "__UNDEFINED__", "cache": true, "allows_loop": false}], "field_order": ["json_str", "remove_control_chars", "normalize_unicode", "validate_json"], "beta": false, "legacy": false, "edited": false, "metadata": {}, "tool_mode": false, "category": "processing", "key": "JSONCleaner", "score": 0.007568328950209746, "lf_version": "1.1.5"}, "showNode": true, "type": "JSONCleaner", "id": "JSONCleaner-7Yu2E"}, "selected": false, "measured": {"width": 320, "height": 395}}, {"id": "ChatOutput-QUqrf", "type": "genericNode", "position": {"x": 1338.4909491016854, "y": 22.666656854835693}, "data": {"node": {"template": {"_type": "Component", "background_color": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "background_color", "value": "", "display_name": "Background Color", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The background color of the icon.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "chat_icon": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "chat_icon", "value": "", "display_name": "Icon", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The icon of the message.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "code": {"type": "code", "required": true, "placeholder": "", "list": false, "show": true, "multiline": true, "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n", "fileTypes": [], "file_path": "", "password": false, "name": "code", "advanced": true, "dynamic": true, "info": "", "load_from_db": false, "title_case": false}, "data_template": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "data_template", "value": "{text}", "display_name": "Data Template", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "input_value": {"trace_as_input": true, "tool_mode": false, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "input_value", "value": "", "display_name": "Text", "advanced": false, "input_types": ["Message"], "dynamic": false, "info": "Message to be passed as output.", "title_case": false, "type": "str", "_input_type": "MessageInput"}, "sender": {"tool_mode": false, "trace_as_metadata": true, "options": ["Machine", "User"], "options_metadata": [], "combobox": false, "dialog_inputs": {}, "required": false, "placeholder": "", "show": true, "name": "sender", "value": "Machine", "display_name": "Sender Type", "advanced": true, "dynamic": false, "info": "Type of sender.", "title_case": false, "type": "str", "_input_type": "DropdownInput"}, "sender_name": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "sender_name", "value": "AI", "display_name": "Sender Name", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "Name of the sender.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "session_id": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "session_id", "value": "", "display_name": "Session ID", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The session ID of the chat. If empty, the current session ID parameter will be used.", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}, "should_store_message": {"tool_mode": false, "trace_as_metadata": true, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "should_store_message", "value": true, "display_name": "Store Messages", "advanced": true, "dynamic": false, "info": "Store the message in the history.", "title_case": false, "type": "bool", "_input_type": "BoolInput"}, "text_color": {"tool_mode": false, "trace_as_input": true, "trace_as_metadata": true, "load_from_db": false, "list": false, "list_add_label": "Add More", "required": false, "placeholder": "", "show": true, "name": "text_color", "value": "", "display_name": "Text Color", "advanced": true, "input_types": ["Message"], "dynamic": false, "info": "The text color of the name", "title_case": false, "type": "str", "_input_type": "MessageTextInput"}}, "description": "Display a chat message in the Playground.", "icon": "MessagesSquare", "base_classes": ["Message"], "display_name": "Chat Output", "documentation": "", "minimized": true, "custom_fields": {}, "output_types": [], "pinned": false, "conditional_paths": [], "frozen": false, "outputs": [{"types": ["Message"], "selected": "Message", "name": "message", "display_name": "Message", "method": "message_response", "value": "__UNDEFINED__", "cache": true, "allows_loop": false}], "field_order": ["input_value", "should_store_message", "sender", "sender_name", "session_id", "data_template", "background_color", "chat_icon", "text_color"], "beta": false, "legacy": false, "edited": false, "metadata": {}, "tool_mode": false, "lf_version": "1.1.5"}, "showNode": true, "type": "ChatOutput", "id": "ChatOutput-QUqrf"}, "selected": false, "measured": {"width": 320, "height": 229}, "dragging": false}], "edges": [{"source": "ChatInput-dcPER", "sourceHandle": "{\u0153dataType\u0153:\u0153ChatInput\u0153,\u0153id\u0153:\u0153ChatInput-dcPER\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "Prompt-pe0FQ", "targetHandle": "{\u0153fieldName\u0153:\u0153content\u0153,\u0153id\u0153:\u0153Prompt-pe0FQ\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "content", "id": "Prompt-pe0FQ", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "ChatInput", "id": "ChatInput-dcPER", "name": "message", "output_types": ["Message"]}}, "id": "reactflow__edge-ChatInput-dcPER{\u0153dataType\u0153:\u0153ChatInput\u0153,\u0153id\u0153:\u0153ChatInput-dcPER\u0153,\u0153name\u0153:\u0153message\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-Prompt-pe0FQ{\u0153fieldName\u0153:\u0153content\u0153,\u0153id\u0153:\u0153Prompt-pe0FQ\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "animated": false, "className": "", "selected": false}, {"source": "Prompt-pe0FQ", "sourceHandle": "{\u0153dataType\u0153:\u0153Prompt\u0153,\u0153id\u0153:\u0153Prompt-pe0FQ\u0153,\u0153name\u0153:\u0153prompt\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "OpenAIModel-nDDz9", "targetHandle": "{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153OpenAIModel-nDDz9\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "input_value", "id": "OpenAIModel-nDDz9", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "Prompt", "id": "Prompt-pe0FQ", "name": "prompt", "output_types": ["Message"]}}, "id": "reactflow__edge-Prompt-pe0FQ{\u0153dataType\u0153:\u0153Prompt\u0153,\u0153id\u0153:\u0153Prompt-pe0FQ\u0153,\u0153name\u0153:\u0153prompt\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-OpenAIModel-nDDz9{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153OpenAIModel-nDDz9\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "animated": false, "className": "", "selected": false}, {"source": "OpenAIModel-nDDz9", "sourceHandle": "{\u0153dataType\u0153:\u0153OpenAIModel\u0153,\u0153id\u0153:\u0153OpenAIModel-nDDz9\u0153,\u0153name\u0153:\u0153text_output\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "JSONCleaner-7Yu2E", "targetHandle": "{\u0153fieldName\u0153:\u0153json_str\u0153,\u0153id\u0153:\u0153JSONCleaner-7Yu2E\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "json_str", "id": "JSONCleaner-7Yu2E", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "OpenAIModel", "id": "OpenAIModel-nDDz9", "name": "text_output", "output_types": ["Message"]}}, "id": "reactflow__edge-OpenAIModel-nDDz9{\u0153dataType\u0153:\u0153OpenAIModel\u0153,\u0153id\u0153:\u0153OpenAIModel-nDDz9\u0153,\u0153name\u0153:\u0153text_output\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-JSONCleaner-7Yu2E{\u0153fieldName\u0153:\u0153json_str\u0153,\u0153id\u0153:\u0153JSONCleaner-7Yu2E\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "animated": false, "className": "", "selected": false}, {"source": "JSONCleaner-7Yu2E", "sourceHandle": "{\u0153dataType\u0153:\u0153JSONCleaner\u0153,\u0153id\u0153:\u0153JSONCleaner-7Yu2E\u0153,\u0153name\u0153:\u0153output\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}", "target": "ChatOutput-QUqrf", "targetHandle": "{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153ChatOutput-QUqrf\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "data": {"targetHandle": {"fieldName": "input_value", "id": "ChatOutput-QUqrf", "inputTypes": ["Message"], "type": "str"}, "sourceHandle": {"dataType": "JSONCleaner", "id": "JSONCleaner-7Yu2E", "name": "output", "output_types": ["Message"]}}, "id": "reactflow__edge-JSONCleaner-7Yu2E{\u0153dataType\u0153:\u0153JSONCleaner\u0153,\u0153id\u0153:\u0153JSONCleaner-7Yu2E\u0153,\u0153name\u0153:\u0153output\u0153,\u0153output_types\u0153:[\u0153Message\u0153]}-ChatOutput-QUqrf{\u0153fieldName\u0153:\u0153input_value\u0153,\u0153id\u0153:\u0153ChatOutput-QUqrf\u0153,\u0153inputTypes\u0153:[\u0153Message\u0153],\u0153type\u0153:\u0153str\u0153}", "animated": false, "className": "", "selected": false}], "viewport": {"x": 216.15991523133857, "y": 235.07330291246518, "zoom": 0.45327300464614173}}, "is_component": false, "updated_at": "2025-03-24T05:41:51+00:00", "webhook": false, "endpoint_name": null, "tags": null, "locked": false, "id": "0b616375-3aaa-4716-89b0-1b763e880a27", "user_id": "24e4b9b7-973b-4d32-8618-2f1b6b6b61f9", "folder_id": "a91f2823-6f82-4a9b-b6ed-222b8ef6e7f1"}